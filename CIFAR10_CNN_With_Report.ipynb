{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602cffa6",
   "metadata": {},
   "source": [
    "# CIFAR-10 Image Classification Report\n",
    "\n",
    "This notebook presents a comprehensive report on building, training, and evaluating a Convolutional Neural Network (CNN) for image classification using the CIFAR-10 dataset...\n",
    "\n",
    "**Objectives:**\n",
    "- Understand the CIFAR-10 dataset and its class distribution\n",
    "- Implement data preprocessing and augmentation techniques...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ba85d5",
   "metadata": {},
   "source": [
    "## 1. Adding Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. adding libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce95022",
   "metadata": {},
   "source": [
    "## 2. Loading CIFAR-10 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. loading cifar10 images\n",
    "(train_imgs, train_lbls), (test_imgs, test_lbls) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9fb1a",
   "metadata": {},
   "source": [
    "## 3. Checking Image Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc62912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. testing images\n",
    "print(f\"Training: {train_imgs.shape}, Testing: {test_imgs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section3",
   "metadata": {},
   "source": [
    "![Training and Testing Shapes](images/1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d5f7c",
   "metadata": {},
   "source": [
    "## 4. Defining Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e1462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. classes for cifar10 images\n",
    "cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491f611",
   "metadata": {},
   "source": [
    "## 5. Class Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9197db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. classcounts\n",
    "counts = np.bincount(train_lbls.flatten())\n",
    "plt.figure(figsize=(7,3))\n",
    "sns.barplot(x=cifar_classes, y=counts)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"NO: of images\")\n",
    "plt.title(\"Class Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section5",
   "metadata": {},
   "source": [
    "![Class Distribution](images/2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a476bf1",
   "metadata": {},
   "source": [
    "## 6. Display Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. display grid for samples\n",
    "plt.figure(figsize=(7,7))\n",
    "for idx in range(12):\n",
    "    plt.subplot(3,4,idx+1)\n",
    "    plt.imshow(train_imgs[idx])\n",
    "    plt.title(cifar_classes[train_lbls[idx,0]])\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Sample Images from Training Set\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section6",
   "metadata": {},
   "source": [
    "![Sample Training Images](images/3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f03f1c7",
   "metadata": {},
   "source": [
    "## 7. Normalizing Pixel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b9610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. normalizing pixel values to (0,1)\n",
    "train_imgs = train_imgs.astype('float32')/255.0\n",
    "test_imgs = test_imgs.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca892c4",
   "metadata": {},
   "source": [
    "## 8. One-Hot Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. one-hot encode labels\n",
    "train_lbls = to_categorical(train_lbls, num_classes=10)\n",
    "test_lbls = to_categorical(test_lbls, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c996fc",
   "metadata": {},
   "source": [
    "## 9. Setting Up Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. setup of imagedatagen for training\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f35ba",
   "metadata": {},
   "source": [
    "## 10. Creating Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0eea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. augmented batches gen\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_imgs, val_imgs, train_lbls, val_lbls = train_test_split(\n",
    "    train_imgs, train_lbls, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_gen = augmenter.flow(train_imgs, train_lbls, batch_size=64, shuffle=True)\n",
    "val_gen = ImageDataGenerator().flow(val_imgs, val_lbls, batch_size=64)\n",
    "test_gen = ImageDataGenerator().flow(test_imgs, test_lbls, batch_size=64)"
   ]
  },
  {
    "cell_type": "markdown",
    "id": "initializing-cnn-model",
    "metadata": {},
    "source": [
      "## 11. Initializing CNN Model"
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "id": "cnn-model-definition",
    "metadata": {},
    "outputs": [],
    "source": [
      "from tensorflow.keras import Model, layers\n",
      "\n",
      "class CIFAR(Model):\n",
      "    def __init__(self):\n",
      "        super().__init__()\n",
      "        # A layer\n",
      "        self.convA = layers.Conv2D(32, 3, padding='same')\n",
      "        self.bnA = layers.BatchNormalization()\n",
      "        self.reluA = layers.ReLU()\n",
      "        self.convA1 = layers.Conv2D(32, 3, padding='same')\n",
      "        self.bnA1 = layers.BatchNormalization()\n",
      "        self.reluA1 = layers.ReLU()\n",
      "        self.poolA = layers.MaxPooling2D()\n",
      "        self.dropA = layers.Dropout(0.1)\n",
      "\n",
      "        # B layer\n",
      "        self.convB = layers.Conv2D(64, 3, padding='same')\n",
      "        self.bnB = layers.BatchNormalization()\n",
      "        self.reluB = layers.ReLU()\n",
      "        self.convB1 = layers.Conv2D(64, 3, padding='same')\n",
      "        self.bnB1 = layers.BatchNormalization()\n",
      "        self.reluB1 = layers.ReLU()\n",
      "        self.poolB = layers.MaxPooling2D()\n",
      "        self.dropB = layers.Dropout(0.2)\n",
      "\n",
      "        # C layer\n",
      "        self.convC = layers.Conv2D(128, 3, padding='same')\n",
      "        self.bnC = layers.BatchNormalization()\n",
      "        self.reluC = layers.ReLU()\n",
      "        self.convC1 = layers.Conv2D(128, 3, padding='same')\n",
      "        self.bnC1 = layers.BatchNormalization()\n",
      "        self.reluC1 = layers.ReLU()\n",
      "        self.poolC = layers.MaxPooling2D()\n",
      "        self.dropC = layers.Dropout(0.3)\n"
    ]
  },
  {
    "cell_type": "markdown",
    "id": "classifier-head",
    "metadata": {},
    "source": [
      "## 12. D Classifier Head"
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "id": "forward-call",
    "metadata": {},
    "outputs": [],
    "source": [
      "        # D Classifier head\n",
      "        self.poolD = layers.GlobalAveragePooling2D()\n",
      "        self.dense2 = layers.Dense(10, activation='softmax')"
    ]
  },
  {
    "cell_type": "markdown",
    "id": "forward-pass",
    "metadata": {},
    "source": [
      "## 13. Defining the Forward Pass"
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "id": "forward-call",
    "metadata": {},
    "outputs": [],
    "source": [
      "    def call(self, x, training=False):\n",
      "        x = self.convA(x)\n",
      "        x = self.bnA(x, training=training)\n",
      "        x = self.reluA(x)\n",
      "        x = self.convA1(x)\n",
      "        x = self.bnA1(x, training=training)\n",
      "        x = self.reluA1(x)\n",
      "        x = self.poolA(x)\n",
      "        x = self.dropA(x, training=training)\n",
      "\n",
      "        x = self.convB(x)\n",
      "        x = self.bnB(x, training=training)\n",
      "        x = self.reluB(x)\n",
      "        x = self.convB1(x)\n",
      "        x = self.bnB1(x, training=training)\n",
      "        x = self.reluB1(x)\n",
      "        x = self.poolB(x)\n",
      "        x = self.dropB(x, training=training)\n",
      "\n",
      "        x = self.convC(x)\n",
      "        x = self.bnC(x, training=training)\n",
      "        x = self.reluC(x)\n",
      "        x = self.convC1(x)\n",
      "        x = self.bnC1(x, training=training)\n",
      "        x = self.reluC1(x)\n",
      "        x = self.poolC(x)\n",
      "        x = self.dropC(x, training=training)\n",
      "\n",
      "        x = self.poolD(x)\n",
      "        x = self.dense2(x)\n",
      "\n",
      "        return x"
    ]
  },
  {
   "cell_type": "markdown",
   "id": "6d08c539",
   "metadata": {},
   "source": [
    "## 14. Instantiating and Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87365179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14. instantiate model\n",
    "model = CIFAR()\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=20000,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd9fed0",
   "metadata": {},
   "source": [
    "## 15. Training the Model with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f01e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15. training the model with callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section15",
   "metadata": {},
   "source": [
    "![Training Progress](images/4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9ef9b",
   "metadata": {},
   "source": [
    "## 16. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48555e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16. evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pred_probs = model.predict(test_imgs, batch_size=64)\n",
    "pred_labels = np.argmax(pred_probs, axis=1))\n",
    "true_labels = np.argmax(test_lbls, axis=1)\n",
    "\n",
    "print(\"Model Performance\")\n",
    "print(classification_report(true_labels, pred_labels, target_names=cifar_classes, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section16",
   "metadata": {},
   "source": [
    "![Classification Report](images/5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1ef29",
   "metadata": {},
   "source": [
    "## 17. Confusion Matrix Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17. confusion matrix heatmap\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm',\n",
    "            xticklabels=cifar_classes, yticklabels=cifar_classes)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix: which classes get confused!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section5",
   "metadata": {},
   "source": [
    "![HEATMAP](images/6.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1ef29",
   "metadata": {},
   "source": [
    "## 18. Baseline Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd105e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18. baseline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(64, 3, activation='relu', padding='same', input_shape=(32,32,3)))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(128, 3, activation='relu', padding='same'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "base = baseline_model()\n",
    "base_history = base.fit(train_gen, validation_data=val_gen, epochs=20, callbacks=callbacks)\n",
    "\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"custom CNN\")\n",
    "plt.plot(base_history.history[\"val_accuracy\"], label=\"baseline\")\n",
    "plt.title(\"Validation Accuracy Comparison\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section5",
   "metadata": {},
   "source": [
    "![BASELINE EPOCHS](images/7.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section5",
   "metadata": {},
   "source": [
    "![BASELINE VALIDATIONS](images/8.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f1a90",
   "metadata": {},
   "source": [
    "## 19. Validation Accuracy and Loss Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0beb2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19. results and visualizations\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history[\"loss\"], label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val\")\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section5",
   "metadata": {},
   "source": [
    "![Class Distribution](images/9.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef723c",
   "metadata": {},
   "source": [
    "## 20. Misclassified Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fedfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20. misleading predictions\n",
    "mis_index = np.where(pred_labels != np.argmax(test_lbls, axis=1))[0]\n",
    "plt.figure(figsize=(7,7))\n",
    "for idx in range(12):\n",
    "    plt.subplot(3,4,idx+1)\n",
    "    plt.imshow(test_imgs[mis_index[idx]])\n",
    "    plt.title(f\"True: {cifar_classes[np.argmax(test_lbls[mis_index[idx]], axis=0)]}\\n\"\n",
    "              f\"Pred: {cifar_classes[pred_labels[mis_index[idx]]]}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Misclassified Images\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section5",
   "metadata": {},
   "source": [
    "![Class Distribution](images/10.PNG)"
   ]
  },
{
   "cell_type": "code",
   "execution_count": null,
   "id": "64hedfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21. Correct predictions\n",
    "correct_index = np.where(pred_labels == np.argmax(test_lbls, axis=1))[0]\n",
    "plt.figure(figsize=(7,7))\n",
    "for idx in range(12):\n",
    "    plt.subplot(3,4,idx+1)\n",
    "    plt.imshow(test_imgs[correct_index[idx]])\n",
    "    plt.title(f\"True: {cifar_classes[np.argmax(test_lbls[correct_index[idx]], axis=0)]}\\n\"\n",
    "              f\"Pred: {cifar_classes[pred_labels[correct_index[idx]]]}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Correctly Predicted Images\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "added-after-section5",
   "metadata": {},
   "source": [
    "![Class Distribution](images/11.PNG)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
